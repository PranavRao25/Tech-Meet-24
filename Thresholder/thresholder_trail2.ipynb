{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Initialize the T5 model and tokenizer\n",
        "model_name = \"geektech/flan-t5-small-gpt4-ce\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define the prompt template\n",
        "def generate_relevance_prompt(question, document):\n",
        "    return (\n",
        "            f\"You are a grader assessing the relevance of a retrieved document to a user question. \"\n",
        "            f\"User question: {question} \"\n",
        "            f\"Retrieved document: {document} \"\n",
        "            f\"compare the semantic meaning of both and\"\n",
        "            f\"Rate the relevance on a scale from -1.0 to 1.0 where -1.0 means not relevant at all and 1.0 means highly relevant.\"\n",
        "    )\n",
        "\n",
        "# Function to check relevance and apply a threshold\n",
        "def check_relevance_with_threshold(question, context, threshold=50):\n",
        "    # Generate the prompt for relevance scoring\n",
        "    prompt = generate_relevance_prompt(question, context)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs[\"input_ids\"], max_length=10)  # Increase max_length if the response is longer\n",
        "\n",
        "    # Decode the output and try to convert it to a score\n",
        "    relevance_score_text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "    print(relevance_score_text)\n",
        "\n",
        "    try:\n",
        "        # Convert the text response to a numerical score\n",
        "        relevance_score = float(relevance_score_text)\n",
        "    except ValueError:\n",
        "        # If conversion fails, assume a default score (optional)\n",
        "        relevance_score = 0.0\n",
        "\n",
        "    # Check if the score meets the threshold for relevance\n",
        "    is_relevant = relevance_score >= threshold\n",
        "    return relevance_score, is_relevant\n",
        "\n",
        "# Example question and context\n",
        "questions = [\"Who was the producer of Escape?\"]\n",
        "# # contexts = [\"Tommy Rettig, and Brian Keith. The announcers were Jack McCoy and Elliott Lewis. Escape (1950 TV series) Escape was a 30-minute live American dramatic anthology television series produced and directed for CBS by Wyllis Cooper. Narrated by William Conrad, the series was the television counterpart to a successful CBS Radio series of the same name (1947–54). There were a total of thirteen episodes airing on CBS from January 5, 1950 to March 30, 1950. According to \\\"The Complete Directory to Prime Time Network and Cable TV Shows 1946–Present\\\", the show's stories \\\"depicted people attempting to deal with danger, the supernatural\"]\n",
        "# # questions=[\"Who was the producer of Escape?\"]\n",
        "# contexts=[\"mumbai is the capital of country\"]\n",
        "# questions = [\"What is the capital of France?\"]\n",
        "    # contexts = [\"start coding be prepared\", \"Paris is the capital of France.\"]\n",
        "contexts = [\n",
        "        \"Paris is the capital of France.\"\n",
        "        ]\n",
        "# Define the threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Check relevance for each question-context pair\n",
        "for question, context in zip(questions, contexts):\n",
        "    relevance_score, is_relevant = check_relevance_with_threshold(question, context, threshold)\n",
        "    print(f\"Question: '{question}'\\nDocument: '{context}'\\nRelevance Score: {relevance_score}\\nIs Relevant: {is_relevant}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8_BbY4lsHvn",
        "outputId": "a93afa4f-1aa9-42d1-d848-0fb023e01ca5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "Question: 'Who was the producer of Escape?'\n",
            "Document: 'Paris is the capital of France.'\n",
            "Relevance Score: 1.0\n",
            "Is Relevant: True\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class RelevanceEvaluator:\n",
        "    def __init__(self, model_path, device=\"cpu\"):\n",
        "        # Load the model and tokenizer\n",
        "        self.device = device\n",
        "        self.tokenizer, self.model = self.load_model(model_path)\n",
        "\n",
        "    def load_model(self, model_path):\n",
        "        # Initialize tokenizer and model\n",
        "        tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
        "        model = T5ForSequenceClassification.from_pretrained(model_path, num_labels=1)\n",
        "        model.to(self.device)\n",
        "        model.eval()\n",
        "        return tokenizer, model\n",
        "\n",
        "    def evaluate_relevance(self, question, contexts):\n",
        "        # Generate relevance scores for each context in relation to the question\n",
        "        scores = []\n",
        "        for context in tqdm(contexts, desc=\"Evaluating contexts\"):\n",
        "            input_text = f\"{question} [SEP] {context}\"\n",
        "            inputs = self.tokenizer(input_text, return_tensors=\"pt\", padding=\"max_length\", max_length=512)\n",
        "            with torch.no_grad():\n",
        "                output = self.model(inputs[\"input_ids\"].to(self.device), attention_mask=inputs[\"attention_mask\"].to(self.device))\n",
        "            # Append the relevance score for the context\n",
        "            scores.append(float(output.logits.cpu()))\n",
        "        print(scores)\n",
        "        return scores\n",
        "\n",
        "    def flag_relevance(self, scores, threshold1, threshold2):\n",
        "        # Convert scores into relevance flags based on thresholds\n",
        "        flags = []\n",
        "        for score in scores:\n",
        "            if score >= threshold1:\n",
        "                flags.append(2)  # High relevance\n",
        "            elif score >= threshold2:\n",
        "                flags.append(1)  # Moderate relevance\n",
        "            else:\n",
        "                flags.append(0)  # Low relevance\n",
        "        return flags\n",
        "\n",
        "    def check_context_relevance(self, question, contexts, threshold1, threshold2):\n",
        "        # Main method to evaluate and flag relevance for each context\n",
        "        scores = self.evaluate_relevance(question, contexts)\n",
        "        flags = self.flag_relevance(scores, threshold1, threshold2)\n",
        "        return flags\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define model path and initialize the relevance evaluator\n",
        "    model_path = \"google/flan-t5-base\"\n",
        "    evaluator = RelevanceEvaluator(model_path, device=\"cpu\")\n",
        "\n",
        "    # Define input question, list of contexts, and threshold values\n",
        "    question = \"What is the capital of France?\"\n",
        "    # contexts = [\"start coding be prepared\", \"Paris is the capital of France.\"]\n",
        "    contexts = [\n",
        "        \"Escape Artists Escape Artists Productions, LLC, commonly known as Escape Artists and distinct from Escape Artists, Inc. (pod caster), is an independently financed motion picture and television production company with a first look non-exclusive deal at Sony Pictures Entertainment, headed by partners Steve Tisch, Todd Black, and Jason Blumenthal. In 2001, Todd Black and Jason Blumenthal’s Black & Blu merged with the Steve Tisch Company to form Escape Artists. The first produced movie under the Escape Artists banner was \\\"A Knight's Tale\\\", starring Heath Ledger in 2001. In the fall of 2005, Escape Artists released \\\"The Weather Man\\\", directed by\",\n",
        "        \"Tommy Rettig, and Brian Keith. The announcers were Jack McCoy and Elliott Lewis. Escape (1950 TV series) Escape was a 30-minute live American dramatic anthology television series produced and directed for CBS by Wyllis Cooper. Narrated by William Conrad, the series was the television counterpart to a successful CBS Radio series of the same name (1947–54). There were a total of thirteen episodes airing on CBS from January 5, 1950 to March 30, 1950. According to \\\"The Complete Directory to Prime Time Network and Cable TV Shows 1946–Present\\\", the show's stories \\\"depicted people attempting to deal with danger, the supernatural\",\n",
        "        \"cat chases rat so rat runs\",\n",
        "        \"Paris is the capital of France.\"\n",
        "        ]\n",
        "    threshold1 = 0.5  # Threshold for high relevance\n",
        "    threshold2 = 0.1  # Threshold for moderate relevance\n",
        "\n",
        "    # Run the relevance evaluation\n",
        "    relevance_flags = evaluator.check_context_relevance(question, contexts, threshold1, threshold2)\n",
        "    print(\"Relevance Flags:\", relevance_flags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtajRLW5o3SC",
        "outputId": "4283cfb5-e415-4504-ae4d-6cb3fc6b875f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google/flan-t5-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Evaluating contexts: 100%|██████████| 4/4 [00:18<00:00,  4.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.028868883848190308, 0.10891035199165344, 0.08477643132209778, 0.036076128482818604]\n",
            "Relevance Flags: [0, 1, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "paijGWv8-rWd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}